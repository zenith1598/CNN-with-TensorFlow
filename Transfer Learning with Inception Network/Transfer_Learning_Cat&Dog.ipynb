{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "49562cde-dc3d-476c-8eaa-cb53084f0851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11807
        }
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-04 10:55:37--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.25.80, 2404:6800:4004:80b::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.25.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  50.6MB/s    in 1.7s    \n",
            "\n",
            "2019-06-04 10:55:39 (50.6 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n",
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "09135bc1-6370-4d81-af96-d4e5956c2846"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "71e965e5-890d-457c-dfc9-badeb0710ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "       -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join( base_dir, 'train')\n",
        "validation_dir = os.path.join( base_dir, 'validation')\n",
        "\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-04 11:10:19--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.25.208, 2404:6800:4004:818::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.25.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "\r          /tmp/cats   0%[                    ]       0  --.-KB/s               \r         /tmp/cats_   6%[>                   ]   4.01M  16.2MB/s               \r        /tmp/cats_a  48%[========>           ]  32.01M  65.2MB/s               \r       /tmp/cats_an  67%[============>       ]  44.31M  64.1MB/s               \r/tmp/cats_and_dogs_ 100%[===================>]  65.43M  83.3MB/s    in 0.8s    \n",
            "\n",
            "2019-06-04 11:10:20 (83.3 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "e5ba0a5c-d28e-4bcb-ad9d-a819a8faa7ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1129
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 20,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "50/50 [==============================] - 5s 104ms/step - loss: 0.2104 - acc: 0.9330\n",
            " - 24s - loss: 0.5172 - acc: 0.7535 - val_loss: 0.2104 - val_acc: 0.9330\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 5s 95ms/step - loss: 0.2069 - acc: 0.9440\n",
            " - 20s - loss: 0.3749 - acc: 0.8315 - val_loss: 0.2069 - val_acc: 0.9440\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 5s 94ms/step - loss: 0.5815 - acc: 0.8980\n",
            " - 19s - loss: 0.3562 - acc: 0.8465 - val_loss: 0.5815 - val_acc: 0.8980\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 5s 93ms/step - loss: 0.3563 - acc: 0.9310\n",
            " - 19s - loss: 0.3217 - acc: 0.8515 - val_loss: 0.3563 - val_acc: 0.9310\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 5s 91ms/step - loss: 0.2231 - acc: 0.9600\n",
            " - 18s - loss: 0.3054 - acc: 0.8690 - val_loss: 0.2231 - val_acc: 0.9600\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 5s 92ms/step - loss: 0.2281 - acc: 0.9570\n",
            " - 19s - loss: 0.3284 - acc: 0.8650 - val_loss: 0.2281 - val_acc: 0.9570\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 5s 91ms/step - loss: 0.2591 - acc: 0.9550\n",
            " - 19s - loss: 0.2967 - acc: 0.8755 - val_loss: 0.2591 - val_acc: 0.9550\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 5s 92ms/step - loss: 0.2884 - acc: 0.9480\n",
            " - 18s - loss: 0.2963 - acc: 0.8795 - val_loss: 0.2884 - val_acc: 0.9480\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.3252 - acc: 0.9460\n",
            " - 18s - loss: 0.2937 - acc: 0.8775 - val_loss: 0.3252 - val_acc: 0.9460\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 5s 93ms/step - loss: 0.5354 - acc: 0.9330\n",
            " - 19s - loss: 0.2736 - acc: 0.8890 - val_loss: 0.5354 - val_acc: 0.9330\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 5s 91ms/step - loss: 0.4320 - acc: 0.9430\n",
            " - 18s - loss: 0.2789 - acc: 0.8840 - val_loss: 0.4320 - val_acc: 0.9430\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.4026 - acc: 0.9450\n",
            " - 18s - loss: 0.2674 - acc: 0.8885 - val_loss: 0.4026 - val_acc: 0.9450\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.3012 - acc: 0.9550\n",
            " - 18s - loss: 0.2663 - acc: 0.8885 - val_loss: 0.3012 - val_acc: 0.9550\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 5s 92ms/step - loss: 0.2392 - acc: 0.9660\n",
            " - 19s - loss: 0.2532 - acc: 0.8970 - val_loss: 0.2392 - val_acc: 0.9660\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.2735 - acc: 0.9610\n",
            " - 19s - loss: 0.2803 - acc: 0.8945 - val_loss: 0.2735 - val_acc: 0.9610\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 5s 93ms/step - loss: 0.2573 - acc: 0.9620\n",
            " - 19s - loss: 0.2501 - acc: 0.9010 - val_loss: 0.2573 - val_acc: 0.9620\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.3886 - acc: 0.9440\n",
            " - 19s - loss: 0.2572 - acc: 0.8900 - val_loss: 0.3886 - val_acc: 0.9440\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 5s 91ms/step - loss: 0.3418 - acc: 0.9480\n",
            " - 18s - loss: 0.2485 - acc: 0.9045 - val_loss: 0.3418 - val_acc: 0.9480\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 5s 92ms/step - loss: 0.3494 - acc: 0.9490\n",
            " - 19s - loss: 0.2343 - acc: 0.9125 - val_loss: 0.3494 - val_acc: 0.9490\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.3502 - acc: 0.9530\n",
            " - 18s - loss: 0.2439 - acc: 0.9010 - val_loss: 0.3502 - val_acc: 0.9530\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "1ef8aa9f-d4f0-4535-c246-df481ac4bae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nd865GOJJ3znnYognfeeciyH/D2CIVmpvQAxpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGDc8H7ANWx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}