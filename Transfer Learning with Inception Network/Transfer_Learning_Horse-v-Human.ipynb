{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Answer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11789
        },
        "outputId": "b8820531-dec8-41e6-e98a-1054ca2dc7b6"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-04 11:25:10--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.140.128, 2a00:1450:400c:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.140.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  39.1MB/s    in 2.1s    \n",
            "\n",
            "2019-06-04 11:25:12 (39.1 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "6e37256b-6959-43ec-87e6-7eec37bc22dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8687
        },
        "outputId": "0d9da0f2-693d-4f26-cb90-4d56890a877d"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "b14f4d7d-7b9a-47dc-8f8f-7eadca101fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-04 11:28:55--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.140.128, 2a00:1450:400c:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.140.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   125MB/s    in 1.1s    \n",
            "\n",
            "2019-06-04 11:28:56 (125 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-06-04 11:28:58--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.76.128, 2a00:1450:400c:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.76.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-06-04 11:28:59 (81.0 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "624fe34d-bc36-4570-f365-6858cb0e99f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAYtltrGQbux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "076866e0-8160-40aa-bc2a-65d526860245"
      },
      "source": [
        "train_horses_dir = os.path.join(train_dir, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "1c29effe-f940-4593-9b8d-2d953baec0f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2152
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 3s 205ms/step - loss: 0.0019 - acc: 1.0000\n",
            " - 18s - loss: 0.2756 - acc: 0.8939 - val_loss: 0.0019 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 2s 138ms/step - loss: 0.0311 - acc: 0.9883\n",
            " - 14s - loss: 0.1103 - acc: 0.9474 - val_loss: 0.0311 - val_acc: 0.9883\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 2s 136ms/step - loss: 0.0149 - acc: 0.9922\n",
            " - 14s - loss: 0.1024 - acc: 0.9611 - val_loss: 0.0149 - val_acc: 0.9922\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 2s 135ms/step - loss: 0.0020 - acc: 1.0000\n",
            " - 14s - loss: 0.0640 - acc: 0.9747 - val_loss: 0.0020 - val_acc: 1.0000\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.0222 - acc: 0.9922\n",
            " - 14s - loss: 0.0644 - acc: 0.9805 - val_loss: 0.0222 - val_acc: 0.9922\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.0872 - acc: 0.9766\n",
            " - 14s - loss: 0.0682 - acc: 0.9727 - val_loss: 0.0872 - val_acc: 0.9766\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 2s 130ms/step - loss: 0.0044 - acc: 0.9961\n",
            " - 14s - loss: 0.0337 - acc: 0.9893 - val_loss: 0.0044 - val_acc: 0.9961\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.0124 - acc: 0.9961\n",
            " - 14s - loss: 0.0598 - acc: 0.9805 - val_loss: 0.0124 - val_acc: 0.9961\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 2s 129ms/step - loss: 0.0804 - acc: 0.9883\n",
            " - 14s - loss: 0.0470 - acc: 0.9883 - val_loss: 0.0804 - val_acc: 0.9883\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.0391 - acc: 0.9922\n",
            " - 14s - loss: 0.0543 - acc: 0.9844 - val_loss: 0.0391 - val_acc: 0.9922\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.0709 - acc: 0.9844\n",
            " - 14s - loss: 0.0315 - acc: 0.9912 - val_loss: 0.0709 - val_acc: 0.9844\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.1525 - acc: 0.9688\n",
            " - 14s - loss: 0.0357 - acc: 0.9903 - val_loss: 0.1525 - val_acc: 0.9688\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.1575 - acc: 0.9727\n",
            " - 14s - loss: 0.0067 - acc: 0.9981 - val_loss: 0.1575 - val_acc: 0.9727\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 2s 135ms/step - loss: 0.0485 - acc: 0.9922\n",
            " - 14s - loss: 0.0298 - acc: 0.9942 - val_loss: 0.0485 - val_acc: 0.9922\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 2s 136ms/step - loss: 0.1336 - acc: 0.9727\n",
            " - 15s - loss: 0.0542 - acc: 0.9893 - val_loss: 0.1336 - val_acc: 0.9727\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 2s 135ms/step - loss: 0.0868 - acc: 0.9844\n",
            " - 14s - loss: 0.0343 - acc: 0.9854 - val_loss: 0.0868 - val_acc: 0.9844\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 2s 130ms/step - loss: 0.2978 - acc: 0.9570\n",
            " - 14s - loss: 0.0274 - acc: 0.9942 - val_loss: 0.2978 - val_acc: 0.9570\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 2s 135ms/step - loss: 0.0566 - acc: 0.9922\n",
            " - 14s - loss: 0.0236 - acc: 0.9903 - val_loss: 0.0566 - val_acc: 0.9922\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.0590 - acc: 0.9922\n",
            " - 14s - loss: 0.0186 - acc: 0.9932 - val_loss: 0.0590 - val_acc: 0.9922\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.0870 - acc: 0.9922\n",
            " - 14s - loss: 0.0133 - acc: 0.9951 - val_loss: 0.0870 - val_acc: 0.9922\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 2s 140ms/step - loss: 0.3384 - acc: 0.9570\n",
            " - 14s - loss: 0.0412 - acc: 0.9912 - val_loss: 0.3384 - val_acc: 0.9570\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 2s 130ms/step - loss: 0.0724 - acc: 0.9922\n",
            " - 14s - loss: 0.0106 - acc: 0.9961 - val_loss: 0.0724 - val_acc: 0.9922\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 2s 130ms/step - loss: 0.1455 - acc: 0.9805\n",
            " - 14s - loss: 0.0117 - acc: 0.9942 - val_loss: 0.1455 - val_acc: 0.9805\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.0720 - acc: 0.9922\n",
            " - 14s - loss: 0.0258 - acc: 0.9922 - val_loss: 0.0720 - val_acc: 0.9922\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.4861 - acc: 0.9531\n",
            " - 14s - loss: 0.0179 - acc: 0.9922 - val_loss: 0.4861 - val_acc: 0.9531\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.2647 - acc: 0.9688\n",
            " - 14s - loss: 0.0274 - acc: 0.9942 - val_loss: 0.2647 - val_acc: 0.9688\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 2s 135ms/step - loss: 0.4394 - acc: 0.9570\n",
            " - 14s - loss: 0.0173 - acc: 0.9942 - val_loss: 0.4394 - val_acc: 0.9570\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.1747 - acc: 0.9688\n",
            " - 14s - loss: 0.0141 - acc: 0.9951 - val_loss: 0.1747 - val_acc: 0.9688\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.5011 - acc: 0.9531\n",
            " - 14s - loss: 0.0267 - acc: 0.9971 - val_loss: 0.5011 - val_acc: 0.9531\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.3234 - acc: 0.9648\n",
            " - 14s - loss: 0.0161 - acc: 0.9942 - val_loss: 0.3234 - val_acc: 0.9648\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.1824 - acc: 0.9688\n",
            " - 14s - loss: 0.0081 - acc: 0.9981 - val_loss: 0.1824 - val_acc: 0.9688\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 2s 135ms/step - loss: 0.1819 - acc: 0.9727\n",
            " - 14s - loss: 0.0131 - acc: 0.9942 - val_loss: 0.1819 - val_acc: 0.9727\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 2s 130ms/step - loss: 0.0930 - acc: 0.9805\n",
            " - 14s - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0930 - val_acc: 0.9805\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 2s 139ms/step - loss: 0.1420 - acc: 0.9766\n",
            " - 14s - loss: 0.0342 - acc: 0.9912 - val_loss: 0.1420 - val_acc: 0.9766\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.3353 - acc: 0.9688\n",
            " - 14s - loss: 0.0226 - acc: 0.9922 - val_loss: 0.3353 - val_acc: 0.9688\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.3627 - acc: 0.9688\n",
            " - 14s - loss: 0.0187 - acc: 0.9961 - val_loss: 0.3627 - val_acc: 0.9688\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 2s 132ms/step - loss: 0.1610 - acc: 0.9766\n",
            " - 14s - loss: 0.0178 - acc: 0.9961 - val_loss: 0.1610 - val_acc: 0.9766\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.2200 - acc: 0.9766\n",
            " - 14s - loss: 0.0396 - acc: 0.9873 - val_loss: 0.2200 - val_acc: 0.9766\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 2s 133ms/step - loss: 0.1326 - acc: 0.9805\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            " - 14s - loss: 0.0036 - acc: 0.9990 - val_loss: 0.1326 - val_acc: 0.9805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "00dc6600-234e-4557-ab31-4f9f4ef2607d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl0qu0EOVlQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}